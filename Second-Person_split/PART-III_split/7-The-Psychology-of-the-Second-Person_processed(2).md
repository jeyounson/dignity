# PART III

## 7. The Psychology of the Second Person

We respect persons when we give them standing in our relations with them and recognize their second-personal dignity. But what psychic mechanisms are involved in respect and the second-person standpoint? How is it possible for a capacity that is sensitive, in principle, to claims of free and rational agents as such to be realized in human psychology, naturalistically conceived? Whether there is such a thing as dignity and what it takes to have that status are not, of course, matters of empirical psychology. The thesis of morality as equal accountability is moralphilosophical, not psychological. Still, rival consequentialist moral theories can be lent an air of apparent empirical support and realism by the familiar Humean moral psychology with which they are often associated and hence an apparent default plausibility that Kantian theories rarely seem to enjoy. There is, for some, a lingering sense that any moral theory claiming *a priori* foundations and faculties cannot possibly apply to human beings as we actually are.

This chapter discusses aspects of human psychology that are relevant to morality as equal accountability and to the second-person stance more generally. We have already seen (in Chapters 4 and 5) how familiar reactive attitudes have an implicitly second-personal structure that fits them to practices of mutual accountability. In this chapter, we consider how these interact with other psychic mechanisms that also play crucial supporting roles, most notably, empathy and what Gibbard calls our "normative psychology," namely, the distinctive human capacities concerned with accepting and regulating behavior and feeling by norms (1990: 55–82).

Two caveats are necessary at the outset. First, I should stress again that nothing I say in this chapter is intended to provide direct support for morality as equal accountability or for the existence of second-personal reasons. Any arguments for these ideas must be normative and philosophical.[^1] Nonetheless, to the extent that human behavior can be shown to involve capacities in which second-personal moral notions are psychically realized, so also can these ideas be seen to fit with our psychology, or at least not to be in conflict with it.

Second, although I draw on a steadily increasing literature in experimental psychology, some of my psychological hypotheses are abstract and speculative. To some extent, this is unavoidable. And it is worth noting that the Humean framework similarly employs a more abstract conception of desire than any that can be found in common sense or experimental psychology. In fact, the Humean theory's notion of desire is sufficiently abstract that the phenomena I point to here are likely consistent with the basic "law" of the Humean theory of motivation—which states that all intentional action results from appropriately paired desires and beliefs (Davidson 1980; Smith 1994). The fact remains that the mechanisms I discuss are implicated in desires that are, in Rawls's helpful terms, "principle-dependent" rather than "object-dependent."[^2] Here there will be two crucial points. First, sometimes, perhaps frequently, the desires that help to explain our intentional behavior are among those we have because we accept certain norms of action. And second, some of the norms we evidently accept essentially involve the idea of second-personal authority.

Finally, we should keep in mind a point I made at the end of Chapter 5, namely, that the familiar forms of moral reasoning that are involved in such principles as the Golden Rule and the Categorical Imperative have an intuitive second-personal interpretation. The thought that people ought not to act in ways that fall short of their expectations or implicit demands of others reveals itself in our psychology in all sorts of ways, from the reactive attitudes to more principled moral reasoning of the kind that psychologists of moral development like Kohlberg (1981) have studied. Any denial that these forms of reasoning and the feelings that draw upon them are deep and pervasive aspects of human psychology would seem to be, to quote Bishop Butler, "too glaring a falsity to need being confuted" (1983: I.8).[^3]

### **Desire and Norm**

We can begin by considering the respective motivational roles played by desire, as philosophers normally understand it, and norm acceptance, as Gibbard describes it. I claim, again, that second-personal competence essentially includes the capacity to be guided by norms, especially by second-personal norms that concern the authority to claim and demand. Ultimately I argue that there is yet a further essential element: the ability critically to evaluate second-personal norms one accepts, and competing alternatives, from the standpoint of one mutually accountable person among others and to be guided by those one would endorse from that standpoint.[^4] One way of viewing the argument of this book is as an attempt to show that this is but a more developed version of what is implicit in any second-personal thinking, for example, in reactive attitudes.

Gibbard introduces the idea of norm acceptance through a discussion of cases of weak will. Suppose, for example, that you can't get yourself to stop eating nuts at a party (1990: 56).[^5] On the one hand, you desire to keep eating them. On the other, you think you shouldn't. It doesn't matter for present purposes why. The reasons might relate to health, avoiding boorishness, not taking more than one's share, or whatever. The point is that some conflict exists between your desire for nuts and your normative conviction regarding what there is most reason for you to do. We know, of course, that frequently the nuts win out. But the point is that they don't always and that even when they do, there is usually some conflict. At least some motivation seems to come from accepting that there are weightier reasons to stop eating.[^6]

This is not sufficient to establish that the motivation does not derive from further independent desires, of course. Perhaps it comes in this case from the desire to be healthy or from the desire not to be or to seem a boor. However, there are many reasons for thinking that this cannot always be so in general, that our accepting norms and normative reasons must exert some influence on our behavior that cannot be reduced to that of independently existing desires that are not themselves principledependent.[^7]

One reason is that beliefs and desires can themselves explain behavior as intentional only on the hypothesis that we are usually instrumentally rational, and this will be so *only-if* norms of instrumental rationality play a regulating role (Korsgaard 1986). Lewis Carroll (1895) famously made the analogous point about inference as it applies to belief. Without guidance by some norm of inference, a set of beliefs or believed premises is impotent to yield conclusions. (Of course, beliefs might simply cause further beliefs in some nonrational way, but this wouldn't explain the transition of thought as rational.) If, for example, someone believes *p* and if *p,* then *q,* she cannot conclude *q* unless she follows a norm of inference, *modus ponens,* that takes her from (her beliefs that) *p* and if *p,* then *q,* to (a belief that) *q.* Trying to add a further *modus ponens*-like belief—(if *p* and if *p,* then *q,* then *q*)—will not help, since it will still take following *modus ponens* to get rationally even from these augmented beliefs to a belief that *q.* The rational formation of new beliefs through inference cannot be fully explained by belief, therefore; it also requires regulation by a norm of inference.

The situation is exactly analogous with instrumental reasoning from ends to necessary means.[^8] To reason to a conclusion to take the necessary means to an end, it is required, not just that one have the end and believe some means to be necessary to achieve it, but also that one be regulated by a norm of practical inference that takes one from this desire and belief to the practical conclusion to take the necessary means.[^9] And the only way the end and belief can rationally give rise to a desire to take the means is via a norm of instrumental reasoning that is analogous to *modus ponens.* A further desire to take the necessary means to one's ends will be impotent in itself, for the very same reason that Lewis Carroll pointed to in the theoretical case.

Regulation by norms of these theoretical and practical kinds is thus necessary to explain rational behavior, even in the terms of Humean desire-belief psychology. As important as this phenomenon is, however, it doesn't yet fully capture the way in which norm acceptance is involved when an acceptance that one should or has reason to do something tends to motivate doing it, and such tendency, as in Gibbard's nuts example, conflicts with occurrent desires. The reason is that this necessarily includes accepting not just norms of inference but also norms that can supply premises in practical reasoning, that is, substantive normative reasons for acting. *Modus ponens* and the norm of instrumental reason, as well as such associated norms of coherent theoretical and practical reasoning as the law of non-contradiction and formal decision theory, are best interpreted as norms of "relative rationality" (Darwall 1983: 14–16, 44–49, 66–67; also Darwall 2001). If one has good reason not to believe *p* and if *p,* then *q,* then the fact that one believes *p* and if *p,* then *q* cannot (by *modus ponens*) give one any reason to believe *q.* Rather *modus ponens* transfers whatever rational support there is for the first two beliefs to the third. Believing *q* is rational "relative to" there being reason to believe both *p* and if *p,* then *q,* respectively.

Here again, the situation is exactly analogous in instrumental reasoning. If one has no reason to have an end (and/or no reason to believe that some means is necessary to achieving it), then the mere facts that one has the relevant end and belief can give one no reason whatsoever to take the means. The most that instrumental rationality can require is that one either take the means or give up either the end or the belief about the means' indispensability. The practical analogue of *modus ponens* transfers rational support from the end and the belief to the means. Taking the means is rational relative to there being reason to have the end and to believe that the relevant means is indispensable.[^10]

Our beliefs, desires, and intentions must be more than merely coherent to be supported by reasons. It follows that when we sincerely judge that there is reason to do something or that we ought to do it, we must accept substantive normative claims that go beyond any that follow from norms of coherent belief, desire, and action. And there is good reason to think, moreover, that the influence of accepting such normative judgments, like that of accepting norms of practical inference, cannot be reduced to the influence of independently existing desires.

Particularists like Dancy may insist at this point that the normative reasons we accept frequently resist formulation in universal norms, whereas universalists may hold that if I judge, say, that I should forego the nuts because that is for my good, this commits me to a universal norm of prudence. But these differences don't matter for our purposes. Whether motivational influence comes from acceptance of particular or universal normative claims, what matters is its irreducibility to independently existing desires.[^11] I therefore use "normative acceptance" to refer to the acceptance of either.[^12]

Presently, I point to what I think are important psychic differences between desire and normative acceptance. First, however, we need to note an important logical difference. Desire, as conceived within the Humean framework, takes propositions or possible states of affairs as objects.[^13] Desire and belief are defined by their differing "directions of fit" with respect to a common propositional content or possible state of the world (Anscombe 1957; Platts 1979: 256–257; Smith 1994: 111–119). A belief that *p* represents the world as being such that *p,* and if the world is not such that *p,* the belief is mistaken and should be changed. Beliefs are thus said to have the "mind-to-world" direction of fit; they seek to fit the mind to the world. Desires work the other way around, in a "world-tomind" direction. A desire represents a possible state of affairs that the world should contain (viewed, as it were, from the desire's perspective).

So conceived, desires are *state-of-the-world-regarding* in their nature. To have a desire is to be disposed to bring some state of the world about. It is, we might say, to be *teleologically* disposed. Even when the desired state includes one's performing a specific action as an essential part, even when performing the action comprises the state in its entirety, the motivational influence of the desire is still entirely teleological. One is moved to perform the action as an essential (or the sole) constituent of the state.

Normative acceptance, however, has a different logical structure.[^14] What practical norms and normative reasons for action call for is action pure and simple or, perhaps, a choice or intention to perform an action. Similarly, norms for belief recommend this or that belief; norms for feeling recommend this or that feeling; and so on. Call anything that can be regulated by a norm an "attitude."[^15] And call any being whose attitudes can be normatively regulated, and thus to whom norms can apply, a "subject." Attitudes are states of subjects that subjects can have for reasons, that is, where not only is there some non-rationalizing, say causal, explanation (explaining reason) of their having the attitude, but there is also something that is *the subject's reason* for having it, namely, some consideration or considerations the subject herself takes as a normative reason or reasons and acts on.

So whereas desires are state-of-the-world-regarding, normative acceptance is *attitude-of-a-subject-regarding;* and practical norms are intentionor action-regarding.[^16] Normative acceptance thus motivates intention and action directly, not out of a desire for some state.[^17] Perhaps we should say that it motivates "deontologically." Even when the norm is teleological, like "Bring it about that *p,*" normative acceptance does not motivate teleologically. It can only motivate one to act in conformance with applicable norms or normative reasons, even when these dictate the very same acts one would be moved to by a desire that *p.* And this logical difference gives rise to a psychic difference: unlike the acceptance of a norm recommending that one bring *p* about, a desire that *p* can show itself in disappointment that *p* did not occur, whether or not one was in a position to realize it.

The psychic difference between desire and norm acceptance also reveals itself in our experience in various other ways. One is in the phenomenon of *regret.* Failing to satisfy a desire can give rise to regret *only-if* one thinks there was some reason to have done something to have satisfied the desire.[^18] The most familiar experience is regretting doing something one thinks one shouldn't have done, all things considered—continuing to eat the nuts, for example. But it is also possible to experience regret for things one thinks there was only some reason not to do, but overbalancing reason to do. In these cases, we are likely to say we regret "having" to do what we did rather than that we simply regret doing it, since the latter would imply regret, all things considered. The important point is that failing to act on a desire can move us to regret only to the extent that it engages what we take to be normative reasons for acting.

An additional, second dissimilarity involving regret follows in the wake of desire's and normative acceptance's different logical structures. Both regret and unsatisfied desire are "con attitudes," broadly speaking, but whereas regret is against or "con" some action (or omission), unsatisfied desire is "con" some state. Thus, consider the case where the object of regret is the omission of an action whose performance was an essential constituent of a state you intrinsically desired. Suppose you think that you should have done *A* and you desire (or wish) that you had done *A.* Even in this case, regret at not having done *A* is different from feeling displeased that your doing of *A* didn't take place. The first naturally tends to give rise to dissatisfaction with yourself (as an agent). Displeasure that the state of affairs of your doing *A* did not obtain, however, can occasion dissatisfaction with yourself *only-if* you took it you had some reason to do *A* (even if only because you thought your desiring to do *A* gave you such a reason).

Third, whereas accepting a norm regulating an attitude typically involves some tendency to acquire the relevant attitude in the conditions specified by the norm (Gibbard 1990: 55–82), a desire that one have that attitude does not itself involve a tendency to acquire the relevant state (at least, not directly). Thus, a desire that I believe something cannot itself give rise to the relevant belief, although it can motivate me to look for reasons that would support the belief, on the basis of which I might then acquire it. Desire is a normatively regulable attitude with its own distinctive (right kind of) normative reasons. In desiring that I believe something, it will seem to me that my having the belief would be desirable, that there are reasons for me to desire the state of the world in which I have that belief and reasons therefore to bring that state of the world about. But these are not reasons of the right kind to make the belief credible, nor is it possible by accepting them to form the belief. I can only form the desire that I have the belief. This is another reflection of the "wrong kind of reasons" problem that noted in Chapter 1. Were I, however, to believe that there are epistemic reasons for the belief, then I would accept that this is something I should believe. And it is possible to form a belief on these grounds (even when one can't say more specifically what the reasons are).[^19] Similarly for practical norm acceptance: thinking there is some reason to do something (even when one is unsure what the specific reasons are) involves some tendency so to act or intend. Attitudes that can be regulated by norms, again, are precisely those mental states that subjects can form for reasons—their reasons—that is, considerations they take as normative reasons to have the relevant attitude.[^20]

We should not, however, draw too bright a line between desire and normative acceptance. Desires, again, are among the attitudes that can be normatively regulated. And to play the right role in motivating intentional action (even on the Humean picture) desires can hardly be just brute urges.[^21] They must be more like what Scanlon calls favorable "directed attention." When someone desires *P* in the "directed attention sense," "the thought of *P* keeps occurring to him or her in a favorable light... the person's attention is directed insistently toward considerations that present themselves as counting in favor of *P*" (Scanlon 1998: 37). But this just means, and Scanlon takes it to mean, that when one desires *P* it seems to one as if there are (normative) reasons to desire *P* and hence, owing to the principle of instrumental reason, to bring *P* about.[^22]

Even though this brings desire within the scope of the normative, there is a remaining important difference with normative acceptance, namely, that desires involve seeming normative reasons, whether or not we accept, on reflection, that the reasons actually exist. In the nuts example, your desire to keep eating the nuts conflicts with your acceptance that you have better reasons to stop. You could accept that, of course, and still think there is some reason to keep eating, other things being equal. But to desire to keep eating, you don't have to accept even that *pro tanto* normative judgment. It is enough for desire, even in the directed attention sense, that eating the nuts seem good in some way, that there appears to be some reason to do so. That can be so even if you reject that there is any reason to keep eating. This kind of case is perhaps clearer in sensory experience. Once you are familiar with the illusion, the fact that a stick looks bent in water may not give you any reason to think that it is really bent. The illusory character of the experience doesn't outweigh a still existing reason; it defeats what would otherwise be a reason. And the same thing can happen with desire. The very things that seem attractive to you about eating the nuts might be features or considerations that you reject as any reasons at all, even as they continue to seem attractive.

A related phenomenon can happen with normative acceptance itself when, in Gibbard's words, we are "in the grip of a norm" (1990: 60). Gibbard discusses the phenomenon in connection with Milgram's famous experiments about obedience, which occupy us for different reasons presently. Subjects in the Milgram experiments were told by an authority figure to administer shocks to another subject to test how people learn. The "teacher" was told to respond to "learner"'s mistakes with shocks of increasing severity, beginning at 15 volts and continuing up to 450 volts. In fact, no shocks were actually given, and the learners were really confederates. But this was not, of course, what the subjects believed. And distressingly, a substantial majority of the subjects in the initial setup (approximately two-thirds) administered all the shocks they were ordered to, up to and including 450 volts, with the highest several levels being labeled, "Danger: Severe Shock." Many, however, were obviously upset, conflicted, and obeyed at the higher levels only under protest.[^23]

We naturally respond to these experiments with dismay, judge that the subjects should not have administered the shocks as they were ordered, and hope we wouldn't have done so ourselves were we in their shoes. Gibbard points out, however, that, given the results, we should assume that we well might have, albeit with conflict and reservations. After all, 80 percent of the subjects administered shocks to at least 225 volts (halfway up the shock generator). Gibbard analyzes this case as involving the acceptance of conflicting norms—against harming others and against disobeying authority. But though subjects genuinely accepted norms of both kinds, many were also "in the grip" of a norm of authority in the sense that, in the circumstances, the norm seemed to override and ground weightier reasons than the norm against harm, although this was the reverse of what many of the subjects (on reflection) actually accepted. And it seems possible, moreover, to be, as it were, in the grip of a norm entirely, that is, for it to seem to provide normative reasons, even though we reject it on reflection and judge that it gives no normative reasons whatsoever.

The sort of normative acceptance that is revealed in the Milgram experiments is psychically different from desire. We can say, of course, that the subjects wanted not to disobey, that they wanted not to harm, and that, in the circumstances, they evidently wanted the former more than they did the latter. And in the directed attention sense of desire, at least, we can say that, in having these desires it seemed to them that there were reasons to desire, and thus to bring about, states of the world in which they did not harm. But it seems obvious that the Milgram subjects didn't just want these latter states pure and simple; they wanted them, at least partly, because they thought they shouldn't harm.[^24] Their desires followed their norms; they were principle-dependent rather than object-dependent. And because of this, their psychic conflict, caught between norms dictating conflicting actions, was palpably different from that of someone who merely has conflicting object-dependent desires, that is, desires for two outcomes that cannot simultaneously be realized. It showed itself in forms of agitation, upset, and emotional distress that are quite different from the conflict of someone forced to choose between two alternatives to which she is averse, but which otherwise violate no norm that she accepts or that grips her.

### **Accepting Moral Norms and the Second Person**

I have been pursuing the evidence, both speculative and empirical, for the human capacity for norm acceptance because it is an essential aspect of second-personal competence. When you and I address second-personal demands to one another, we presuppose that we both have the capacity to accept and act on second-personal norms that ground relevant second-personal reasons irrespectively of our (object-dependent) desires for states of the world. That was an essential aspect even in our first example, when you addressed a demand to someone to get off of your feet. The reason you purported to address to him came not from the badness of your being in pain (as this might be represented in a desire that you be free of it) but from a norm proscribing foot treading. And in addressing the reason to him, you consequently assumed that he could accept and act on it irrespectively of any (object-dependent) desire that your feet be free of pain, or even of pain caused by foot treading (that was the agentrelative aspect of the reason).[^25]

What I have said in this chapter so far has concerned (practical) norm acceptance in general. It seems possible, however, to have that capacity while lacking psychic mechanisms that are involved in accepting and recognizing norms that relate to second-personal reasons in particular. To instantiate second-personal competence, the human repertoire must include something, like reactive attitudes, that mediates second-personal accountability, along with the capacity to reflect on and revise these in critically accepting second-personal norms and reasons.

In this connection, Gibbard notes that the emotional manifestations exhibited in the Milgram experiments show not just any norms were in play, but that peculiarly social ones were operating. Violating a prudential norm is unlikely, by itself, to give rise to the sorts of feelings of embarrassment, shame, and guilt that the Milgram subjects evidently felt. If I keep eating the nuts, the thought that I shouldn't because it is bad for me cannot support feelings like these unless I somehow connect it to some ideal of a presentable or morally decent self, so that I am embarrassed by publicly displayed intemperance, or ashamed even when I keep eating the nuts in private, or feel remorse that I never seem to leave enough for others.

Most importantly for our purposes, the norms that seem most obviously involved in the Milgram experiments are second-personal, moral norms. They concern what people have the authority to demand. Norms of obedience are second-personal by their very nature, and I have argued that any moral obligation not to harm is second-personal also. Moreover, an analysis of the experimental setup and results reveals that there were second-personal aspects at play in the responses of subjects that went beyond even the second-personal character of the implicated norms. For example, that the subjects were under instructions they had some obligation to comply with as consenting participants in the experiments was not just made evident to them as an abstract proposition. The authority figure was actually there in the same room with them, and he ordered them. When subjects questioned whether they "had" to go on, or protested about being ordered to, the apparently authoritative experimenter responded with a sequence of increasingly forceful "prods": (1) "Please continue" or "Please go on," (2) "The experiment requires that you continue," (3) "It is absolutely essential that you continue," and (4) "You have no other choice, you *must* go on" (Milgram 1974: 21).

Presently, we shall consider how these prods might have worked psychically. First, however, we should note that they were not the only second-personal element in the experiment.[^26] In the initial setup, the learner was in an adjoining room. He could not be seen and, up until the point when he was administered a shock level of 300 volts, he could not be heard. At this point, however, the learner began audibly pounding on the wall. The pounding continued through 315 volts, after which there was no sound at all coming from the room and, indeed, the learner stopped responding in the learning exercise (which the subjects were instructed to treat as mistakes). In the initial experiment, none of the forty subjects stopped administering shocks before they heard any protest. Five, however, stopped at the first expression of protest. Four stopped on the next round (315 volts), two on the next, and one on each of the next two. So thirteen out of forty subjects (32.5 percent) stopped the shocks within five rounds of the first protest. Moreover, these were 100 percent of the subjects who stopped at all.[^27]

A second setup was identical, except that vocal protests could be heard through the walls throughout. In this version, almost the same number continued until the end—twenty-five instead of twenty-seven. But eight stopped obeying orders to shock in the "Strong Shock" range (135–180 volts), well before the 300 volts that drew the first disobedience in the first setup.

In a third setup, the learner was placed in the same room, a few feet from the subject, and could be both seen and heard. Here thirteen subjects stopped obeying by the end of the "Strong Shock" range, and only a minority, sixteen, administered the full series of shocks (almost 40 percent less full compliance than in the initial setup).

A fourth, and final, setup was identical to the third, except that the learner received a shock *only-when* his hand rested on a shock plate. At the 150-volt level, the learner demanded to be set free and refused to place his hand on the shock plate, whereupon the experimenter ordered the subject to force the victim's hand onto the plate so that he could receive the shocks the subject administered. Remarkably, in this setup twelve subjects continued to the end, but even so this was less than half of the number that did so in the first version. More importantly, twenty (or half the subjects) stopped in the "Strong Shock" range, long before, again, there was any disobedience in the first setup.

Clearly, having protests addressed to them made a significant difference in the subjects' behavior. There was no disobedience in the first setup before any audible protest, and almost 80 percent of the disobedience that did occur took place during or just after the protest (eleven out of thirteen). In the second, protest was audible earlier, and there was also significantly greater disobedience earlier. In the third, protest (and its grounds) were both visibly and audibly evident, and this also significantly increased earlier disobedience. And in the fourth, in which subjects were ordered not just to administer shocks despite the protest but also to enforce a denial of learner's demands to be set free (and arguably to punish them for their demands), the disobedience was greatest of all.

The conflicts that the Milgram subjects experienced were not just between conflicting norms, but between conflicting second-personal norms that grounded demands. Moreover, these demands were at some point or other actually addressed by those the subjects took to have the authority to address them. Both their acceptance of the norms and the address of normatively grounded demands seemed to have psychic consequences. The norms were constant throughout the various setups, as was the experimenter's addressing of orders. What was variable was the evidence and salience of the learners' protests.

But why focus on protest? What varied was not just that but also evidence and salience of pain and of causing pain. Why not say that it was the increasing amount and vividness of the learners' suffering that explained the increased disobedience? But consider: how was the pounding on the wall likely to have been experienced by subjects in the first setup? Presumably, the pain was now getting to be so bad that the learner was asking the subject and the experimenter to stop. As one subject said, "I think he's trying to communicate, he's knocking" (Milgram 1974: 32).

Think about it from the subject's perspective. The learner is, you believe, someone like you who has volunteered to take part in the experiment. You might think that, like you, he feels obligated to take part. You might even think (if only as a rationalization) that it would be unfair to him not to play your role so long as he does. At the least, you certainly would think that whether he has consented to being caused pain is relevant to whether you should cause it to him. These are all second-personal matters. They concern your respective claims and how you and he have the authority to interrelate as mutually accountable equals.

The most significant change in the overall rate of disobedience came when the learner was moved into the same room with the subject. The subject could then see the effects of what he was doing. But also importantly, he was aware, for the first time, of the learner's awareness of him. Even if audible protests were experienced as claims in the first two setups, the conditions made reciprocal recognition impossible. Bringing the learner into the room gave him a presence as someone to whom the subject was accountable—a second-personal advantage the experimenter had in all the setups. Milgram himself notes the possible relevance of this factor:

> Possibly, it is easier to harm a person when he is unable to observe our actions than when he can see what we are doing. His surveillance of the action directed against him may give rise to shame or guilt, which may then serve to curtail the action. Many expressions of language refer to the discomfort or inhibitions that arise in face-to-face attack. It is often said that it is easier to criticize a man "behind his back" than to confront him directly. (1974: 38–39)

The other was present now not just as someone with the standing to demand compliance with a norm requiring that he not be harmed but also as someone with some standing to judge one's compliance with it.[^28]

That second-personal aspects of the situation make a psychic difference seems obvious enough.[^29] But how does this work? And how do the mechanisms involved interact with norm acceptance? No doubt we are, to some extent, moved by desires for others' approval or esteem, or by desires not to be in disagreement with them, even when we care nothing for the standards they employ or have no inclination to share their views. But we are so moved only to some extent. Aristotle noted that we care more about honor and esteem from those we honor and esteem ourselves, and he concluded that this must be because we care independently (and more) about meriting the esteem of those whom we accord the authority to judge us (1980: I.5).

This seems clearly on the mark. When subjects in the Milgram experiments were troubled by the protests of those they were shocking in the same room with them, it seems incredible that they were simply experiencing the discomfort of being regarded in demanding ways. It seems much more likely that, to varying degrees, empathy took them inside their victims' perspectives and that at least some subjects experienced emotions such as shame and guilt in which they empathically regarded themselves as warranting disdain (shame) and/or blame or some other form of second-personal accountability.[^30] How else can we explain the depth and variety of psychic conflict that must have been involved, at least for some? The conflicting external demands of experimenter and victims would likely have been replicated, to varying degrees, empathically within the subjects' own outlooks on themselves.

This fits, again, with what we learned about the role of empathy in second-personal thought in Chapter 3. When I am engaged by another's address second-personally, I inevitably gain a second-personal perspective on myself. I can grasp the other's responses as second-personal *only-if* I see them in relation to my own. And I can do that *only-if* I can see my address as from the other's point of view. By being vulnerable to the other in this way, I am susceptible to appearances as from the other's standpoint. Thus blame can be felt as guilt.[^31] Of course, blame also elicits defensive responses, but that simply proves the same point. If we weren't vulnerable to seeing ourselves as others see us empathically, and hence to blaming ourselves, there would be nothing to defend against.

It is useful to compare here what Mill says about moral sanctions in chapter 3 of *Utilitarianism,* in which he considers the normative (or, as he interprets this, the motivating) force of the principle of utility. "What is its sanction?" he asks. "What are the motives to obey it? Or more specifically, what is the source of its obligation? Whence does it derive its binding force?" (1998: ch. 3, §1). Mill first discusses "external sanctions," within which he includes "hope of favour and the fear of displeasure" from others and from God, whether selfishly or from sympathy or "awe" that inclines us to accord with their will. But Mill gives these short shrift. His chief interest is in the "internal sanction." This "ultimate sanction," Mill says, is "conscience": "a feeling in our own mind; a pain, more or less intense, attendant on violation of duty, which in properly cultivated moral natures rises, in the more serious cases, into shrinking from it as an impossibility" (ch. 3, §3).[^32]

But what makes conscience an internal rather than external sanction? The desire to avoid the displeasure of others is no less internal to the psyche than are feelings of conscience. Why does it make a difference whether the displeasure originates with others or with oneself? Perhaps one can avoid others' displeasure more easily than one can one's own, but Mill's discussion puts no weight on that possibility. What he stresses is the way conscience makes one feel toward the action itself. When moral norms have been internalized, the thought of an action the norms require "presents itself to the mind with the feeling of being *in itself* obligatory" (1998: ch. 3, §1). In a "properly cultivated moral nature," the thought of violating a central norm, strikes one "as an impossibility." What makes conscience an internal sanction, therefore, is not its psychic location. Pain resulting from others' displeasure is no less an internal state than that of being displeased with ourselves. What makes conscience an internal sanction for Mill is rather its object. When we consider that we have done something we think wrong, we don't just have a painful feeling. We have a painful "appearance" that we shouldn't have done what we did, that not doing it was "*in itself* obligatory." We have a putative awareness of having acted contrary to what members of the moral community (and we ourselves as such members) justifiably demand.[^33]

Second-personal address that appeals to shared norms, like remonstrance or blame, can give rise empathically to conscientious feelings that are tied to those norms. Milgram's subjects most likely experienced conflicting normative feelings whose vividness depended on the salience of others' second-personal authority to demand their compliance. Of course, such forms of address can trigger defensive responses also. But part of the reason they can, again, is to defend the self against blame's hitting home and being experienced as guilt. Through empathy we can feel not just others' blame but also that we are to blame.

Thus, one way in which empathy and second-personal address can interact with normative psychology is in the exchange of reactive attitudes and the engendering of conscientious feelings and even normative acceptance. I argued in Chapter 4 that reactive attitudes have a second-personal conceptual structure that calls for a reciprocally recognizing response of which it presupposes its (implicitly addressed) object to be capable. For ordinary human beings, empathy provides the psychological mechanism that funds this presupposition.

To conclude this section, I shall briefly mention one other way in which empathy and second-personal address can figure in our normative psychology, namely, in critical normative discussion, both about individual cases and about norms themselves. Gibbard speculates that norm acceptance has a distinctive evolutionary role that enables human beings to use language and linguistically encoded motivations to solve coordination problems (1990: 64–80). Norm acceptance manifests itself not just in regulating conduct but also in tendencies to avow the norm in contexts of "unconstrained normative discussion" (74). By normative discussion, Gibbard means not just the sort of thing that moralists, moral philosophers, or writers to editorial pages engage in but also something that is virtually ubiquitous in human life, from gossip, to discussion of novels, movies, and sitcoms, to "I was like . . . ; He was like . . ." conversations in which participants display their reactions to others' actions and feelings.[^34] In all of these instances, people negotiate questions of how it makes sense to respond to what people do and what norms for evaluating conduct it makes most sense to accept. And as they do, empathy works to bring others' views inside our perspective so that they can be part of our own critical reflection and not just recorded as what others think. Second-personal accountability is not the only form of social criticism, of course, but surely much of what human beings discuss concerns what they and we can warrantedly expect and demand of one another.

### **Cooperation and Second-Personal Motivation**

Other experiments demonstrate and illustrate the involvement of second-personal psychic mechanisms in human cooperation. Why do people cooperate when it is against their interests to do so? Cooperation is any organized pattern of interaction in which, although the overall pattern advances the cooperating individuals' interests, it nonetheless requires actions from the participants that are less than optimal individually. The classic example is Prisoner's Dilemma, in which the parties do better if both pursue a cooperative strategy, but where the individually optimal strategy is non-cooperative.[^35] Two people face a Prisoner's Dilemma when each profits most by an outcome of their respective actions by which the other profits least (for example, by arming while a hostile foe disarms), but when both profit more if they both do something that is individually suboptimal (say, both disarming). Each party orders his outcomes thus: first: I arm, she disarms; second: we both disarm; third: we both arm; and fourth: I disarm, she arms. In such a situation, advancing one's interests seems unambiguously to recommend arming, since, whatever the other does, one comes out better. But this leads both to an outcome that is worse for both than would have resulted if they had done what is collectively best but individually suboptimal (both disarming).

Because the orthodox view in much contemporary social science, not to mention practical philosophy, has been that self-interested behavior is rational by default, the problem has been to explain why human beings cooperate as much as we evidently do. No motivation beyond preference satisfaction or self-interest is required to explain cooperation in cases with the structure of an "iterated" Prisoner's Dilemma, in which "tit for tat" or some other strategy requring actions that would be suboptimal in a "one shot" game may be most optimal for players even individually (Axelrod 1984). When there are repeated plays, it will pay individually to cooperate now to draw out reciprocating cooperation from fellow players later. But many studies have revealed much human cooperation that cannot be explained by self-interested strategies even of this sort.

There is growing empirical evidence that normative acceptance, including of a distinctively second-personal kind, is frequently involved.[^36] Some especially interesting experiments conducted by Ernst Fehr and Simon Gächter suggest that reactive attitudes are often implicated. Fehr and Gächter (2002) gave groups of four subjects 20 money units (MUs) each, from which each could contribute any amount to a group project and keep any amount she didn't contribute. For every MU invested in the project overall, each of the members earned 0.4 MUs, regardless of her own investment. Thus the investor's return from investing one additional MU was 0.4 MUs (and the expected return of not investing it was 1 MU). If, however, all group members invested no MUS, each would end up with 20 MUs, whereas if all of them invested all of their 20 MUs, each subject would earn 32 MUs.

The variable condition manipulated by the experiment was whether the round of contributions was (known to be) followed by a round in which subjects could anonymously "punish" noncontributors. In this condition, the subjects were given a profile of the others' contributions in the first round without attribution. Each could then assign from 0 to 10 points to any other individual, at a cost of 3 MUs per point to the "punished" subject and 1 MU to the "punishing" subject, respectively. Thus individuals could punish only at cost to themselves.[^37]

Unsurprisingly, when the cooperative contribution rounds were run before subsequent punishment rounds (and this was known in advance), there was a higher level of cooperation than without expected punishment (approximately 13 MUs to 11 MUs). This also increased over time, whereas later cooperation levels without punishment were lower. By the sixth round, the mean cooperation with punishment was above 14 MUs, whereas without punishment, it declined to below 6 MUs. Considered so far, however, these results might be explained simply by a self-interested desire to avoid sanctions.

The more interesting and important finding is that the subjects were prepared to punish at cost to themselves, sometimes at significant cost.[^38] A total of 84.3 percent of the subjects punished at least once during the six periods, 34.3 percent punished more than five times, and 9.3 percent punished more than ten times. Fehr and Gächter term the punishment "altruistic," but by this they evidently mean just that subjects were prepared to hold non-cooperators responsible even at cost to themselves. Subjects reported that they responded with negative emotions to failures to cooperate and that they expected others to respond to them with these same attitudes when they failed to cooperate. Asked how they would feel in hypothetical scenarios in which they are taken advantage of by free riders, subjects predicted they would respond with significant "anger and annoyance," as they predicted others would respond to them if they free rode.

It seems clear enough that reactive attitudes like resentment and indignation were involved that appeared to subjects to be warranted by others' failure to cooperate. Subjects who had these reactive responses would have seen themselves as having a reason, a second-personal reason, to hold the non-cooperators responsible quite independently of reasons of other kinds, self-interest, for example. And evidently enough, these reasons were not only independent of self-interest; for almost 85 percent of the subjects, they apparently outweighed it.[^39]

But if subjects were susceptible to reactive attitudes in responding to others, these feelings would have been no less available by empathic projection in their imagined and actual responses to themselves. And this would then have given them motivations to cooperate themselves that are quite distinct from a desire to avoid sanctions.[^40] For example, such feelings could have functioned as a vivid reminder of a second-personal norm they accepted, which their apparently warranted reactive attitude itself "enforces." Alternatively, or in addition, putting themselves in the shoes of imagined punishers could have given rise empathically to reactive attitudes directed toward themselves.[^41] And in feeling, for example, that they would be to blame for freeloading, they would, in effect, be addressing to themselves a second-personal reason to cooperate.

In any or all of these ways, subjects implicitly saw themselves and others as having, in our terms, the authority to address the second-personal demands that were implicit in the "punishment" they meted out and, therefore, second-personal reasons to comply with these demands. If the threat of resentment provides an important support to cooperation, as these experiments suggest, then the implicit presupposition of second-personal standing must play an important role as well. Indeed, there is evidence that the perceived legitimacy of sanctions, that is, whether they are seen as genuinely authoritative and applied in good faith or simply strategic threats, is itself a significant determinant of levels of cooperation. Fehr and Rockenbach have shown that when sanctions are believed to be applied self-interestedly rather than as expressing valid demands in holding others responsible, this actually diminishes cooperation, that is, makes it less than it would be even in a no-punishment condition.[^42] This is a remarkable result, since from the strategic point of view, (second-personally) unjustifiable sanctions are no less undesirable and sensibly avoided than are justified ones.

Second-personal psychic mechanisms evidently run sufficiently deep that people are willing to forego benefits or incur costs not only to address justified demands but also to defy unjustified ones. And human beings are not the only species in which a response of this sort has been observed. Brosnan and de Waal have found that capuchin monkeys who had been receiving equal rewards for equal effort in an experiment refused to participate further when they saw others beginning to receive more. Noting that there is substantial evidence that "a sense of fairness" is a human universal,[^43] they describe their findings as "supporting an early evolutionary origin for inequity aversion" (2003: 297). But if equity is, as seems clear, a matter of justified claims and demands, it follows that their research supports an early evolutionary origin for second-personal or proto-second-personal psychic mechanisms.

The relevance of the second-person stance to cooperation is further supported by another study by Robert Frank (1988) of the ability to discriminate between cooperators and non-cooperators. After a thirtyminute conversation about whether to cooperate in a one-shot Prisoner's Dilemma in which their subsequent plays were mutually blind, subjects predicted whether their interlocutors would cooperate or not. They were remarkably successful. Sixty percent of the participants who had been predicted to defect did so, and 75 percent of those who had been predicted to cooperate did so (134–145). The likelihood that such a high overall accuracy rate would happen by chance is less than one in a hundred. Moreover, subjects had substantially greater confidence in predictions that subsequently proved correct than in those that turned out to be incorrect. Simply on the basis of a thirty-minute conversation and with no knowledge or experience of their interlocutors' record of cooperation, participants manifested an extraordinary ability to predict whether another person would cooperate for mutual advantage or defect in his own individual interest.

What explains this success? Frank hypothesizes that it has to do with the detection of involuntary bodily symptoms, for example, facial expressions, of emotions that can motivate cooperation. This certainly seems correct. However, his candidates, evidence of sympathy, and emotions like shame and guilt would, in principle, be equally available to anyone who was watching the conversation from a third-person perspective as to those participating in it. And there is experimental evidence that people are not particularly good at detecting lying in general

(Ekman, O'Sullivan, and Frank 1999; Good 1999). There is evidently something about the authenticity of conversation, perhaps especially conversations about whether to cooperate, that enables people to detect it more readily.

I speculate that people in these situations are sensitive to reciprocal recognition, that is, they can detect whether they are being engaged in a serious second-personal deliberation about whether to cooperate in which someone is already according them second-personal authority in that very interaction. Consider: there is an important difference between the motivations that cooperators and defectors respectively have in discussions about whether to cooperate in a one-shot Prisoner's Dilemma. Since a self-interested defector's choice is entirely independent of whether he believes his interlocutor will cooperate or defect (since it will pay him to defect regardless), he has no stake in determining his interlocutor's intentions or motivations.[^44] His only motive in talking is to try to convince his interlocutor to cooperate. A cooperator, however, is motivated both to convince her interlocutor to cooperate and to determine whether he will actually follow through if he says he will, since even a cooperator reasonably wishes to avoid being taken advantage of. In scanning her interlocutor, she must determine whether he is similarly scanning her, that is, whether their scanning is mutual. When she looks into her interlocutor's eyes, does she see him looking back into hers to see whether she is looking into his to see whether she is looking into hers, and so on? A moment's reflection suggests that reciprocal interest of this sort is something we do quite frequently detect. Think of detecting reciprocal romantic or sexual interest. If that is so, cooperators can help assure one another in this way of their willingness to cooperate. In effect, each enables prediction of her willingness to respect an agreement to cooperate by evidently respecting one another in a conversation about whether to cooperate.

A related experimental result is the finding that when subjects converse about what to do in one-shot Prisoner's Dilemmas, cooperation is roughly doubled (Orbell, Dawes, and van de Kragt 1988, 1990). This is notable in itself, of course, since non-cooperation is still evidently the dominant strategy of rational self-interest, even after such a conversation has taken place. After all, the other person will either act as agreed or not, and either way one will do better by defecting. So why is cooperation increased? It seems from these studies that it is not because such discussion heightens moral sensitivity generally, since it evidently does not increase cooperation with strangers. Again, something essentially second-personal seems to be going on. Conversants are likelier to cooperate with each other.

A natural explanation is that such cooperation is simply a further expression and extension of a reciprocal recognition that is already implicit, in some form, when two interlocutors have a serious conversation about what to do. We earlier noted Pettit and Smith's observation (1996) that serious conversation involves some measure of mutual respect and recognition of one another's authority. In discussing, moreover, what they are to do, either individually or together, each purports to recognize the other's authority to participate in such a practical discussion, in effect, a joint deliberation, and hence, to be a source of reasons to act (and not just of reasons to think that certain reasons for acting exist). They recognize one another as a source of claims on their respective wills and conduct and not just on their beliefs, even about what would be sensible action for either or both. They see each other as sources of second-personal reasons. Of course, this could all be simply illusion. I could be trying to get you to believe that I am a cooperator, including to believe that I am looking into your eyes to determine whether you are looking into mine to determine whether I am looking into yours, and so on. But that may not be so easy to fake.

A related possibility is that at least some such conversations give rise to a genuinely collective intention to cooperate, that is, that the conversants come to deliberate together from a "first-person plural" perspective: What shall we do? From this standpoint, cooperation clearly dominates over any other (collective) strategy. In discussing this possibility, Dawes notes that many of the conversations in his studies do indeed take the form of collective deliberations (Orbell, Dawes, and van de Kragt 1988, 1990). But this hypothesis does not conflict with the explanation that cooperation results from reciprocal recognition. According to Margaret Gilbert's "pool of wills" theory (1990, 1996a), in order for two people to decide, say, to take a walk together, each must communicate her willingness to the other (second-personally) to form a plural subject (a "pool of wills") for this purpose. But this means that they must already be reciprocally recognizing each other second-personally. In a slogan: The way to "we" runs through "you" and "I."[^45]

### **Adam Smith on Judgments of Justice**

In Chapter 3, I briefly laid out Adam Smith's anticipation of the contemporary simulationist idea that attributing mental states to others frequently involves an empathic projection into their shoes, as well as Smith's remarks about the distinctively human disposition to "truck, barter, and exchange" and its relation to mutual respect. In the final section of this chapter, I wish to discuss briefly the role of empathic projection (and what Smith called "sympathy") in his theory of moral judgment, specifically, his theory of judgments of justice, since this supports the reflections of the last two sections.

According to Smith, when we judge an agent's action or motive, we do so by projecting (impartially, as though we were anyone) into the agent's perspective and viewing the practical situation as we imagine it to confront her in deliberation. If the person's actual decision and motive match those we simulate under these ideal conditions, then we judge them to be "proper." And when we judge someone's feeling or reaction, we do so from her perspective as a patient, viewing the situation, as we imagine it to face her, as someone responding to it.

It is important that Smithian moral judgments involve an implicit identification with others as having an independent point of view. This already pushes Smith's thought away from the observer-based virtue ethics of Hutcheson and Hume.[^46] Although Smith is a metaethical sentimentalist, like Hume and Hutcheson, it is an important difference between his view and theirs that Smithian judgments of propriety are made not from a third-person perspective but from idealized (impartially disciplined) versions of personal and interpersonal standpoints. What takes Smith even farther from Hutcheson and Hume, and into the second-person standpoint, is his metaethics of justice.[^47]

Injustice, for Smith, is essentially tied to warranted resentment. It is not simply improper conduct but improper conduct to which the proper response is a second-personal reactive feeling to challenge or hold the agent accountable in some way. So on Smith's view, injustice can be judged only by projecting ourselves impartially into the agent's and, crucially, the affected parties' points of view and then considering whether to feel resentment from that perspective. This individual-patientregarding character of justice leads Smith to oppose utilitarian tradeoffs and to hold that resistance to injustice is warranted not by considerations of overall utility but by concern for the "very individual" who would be injured (1982a: 90, 138). Moreover, what we consider from the standpoint of affected parties is whether to respond with a distinctive feeling that itself presupposes mutual accountability between persons. Sympathy with victims' sense of injury involves, according to Smith, not simply a sharing of their sense of having been wronged. It also involves recognition of their authority to challenge the wrong by resisting it, or, failing that, to demand some form of compensation or punishment. It recognizes their second-personal authority to address demands of justice.[^48] We can only judge whether something is properly resented or resisted, therefore, by imagining being in the shoes of the affected parties and considering whether any of us, if reasonable, would feel a reactive, accountabilityseeking sentiment that implicitly lodges some second-personal challenge or complaint and addresses a second-personal reason to respect this challenge.

I bring Smith in at this point to buttress and give a framework for the experimental results of the preceding two sections. When subjects in the Milgram experiment experience emotional conflict between the conflicting claims of an authority figure, on the one hand, and their victims, on the other, it seems implausible that they simply experience these as incompatible external demands. To some extent or other, they likely project into their addressees' respective standpoints and feel the justice of their claims and their authority to blame and hold them accountable. There is experimental evidence, as we have seen, that sanctions increase cooperation when they are seen to be legitimate, but actually decrease it when they are believed only to be applied only strategically (Fehr and Rockenbach 2003). In the one situation, the sanctions are seen to be just, as subjects might judge in Smithian fashion by simulating the resentment and indignation of their (potential) punishers. In the altered situation, the subjects' simulation must lead not to resentment but to some selfinterested motive that cannot support a judgment of justice and the authority to hold accountable, that is, to a reason of the wrong kind.

What armchair moral philosophical and psychological speculation suggests, experimental psychology confirms. That we have distinctively second-personal normative psychological capacities seems, to quote Bishop Butler now in different context, to "be as strongly and plainly proved in all these ways, as it could possibly be proved, supposing there [were these psychic mechanisms] in our nature" (1983: I.6).[^49]

[^1]: For these, see Chapters 10–12.
[^2]: On the basic Humean idea, see Smith 1987 and 1994. For Rawls's distinction, see Rawls 2000: 45–48, 148–152. See also Freeman 1991. For further discussion of these points, see Chapters 9, 10, and 11.<br>Rawls's distinction is similar to, but also importantly different from, Nagel's distinction between "motivated" and "unmotivated" desires (Nagel 1970: 29–30, 38). For Nagel, a desire is motivated if it is based on a reason, if, that is, there is something that is the agent's reason for so desiring. Unmotivated desires are those one brutely has, like the desire for a cool drink, as we say, "for no reason." However, a desire could be motivated but still be object-dependent, namely, if the agent's reasons are drawn from properties of the desire's object or if the agent desires that thing because she think it is intrinsically good. Such desires would be "object-dependent" and "heteronomous" in Kant's sense, since they would come not just from the will's being a "law to itself independently of any property of the objects of volition." (See Kant 1996b: 440 and Chapters 9 through 11 of this book.) "Principle-dependent desires," by contrast, derive from norms of action to which one is subject simply as a rational will and independently of the properties, hence independently of any value of any object of volition, that is, of any representable state of affairs or possible state of the world.

[^3]: The context is Butler's claim that conscience is natural to human beings.
[^4]: As Gibbard would understand it, this would be a capacity to be guided by relevant higher-order norms. See Gibbard on the "authority" of normative judgments (1990: 177– 183).
[^5]: This case has the same structure as the one Plato discusses in the *Republic* of the person who restrains thirst by seeing that there are better reasons not to drink (437d– 439d).
[^6]: For an argument that motivation always comes from reasons to which desires and normative judgments respond, and never from the psychic states of responding to them, see Dancy 2000.
[^7]: There are too many issues to enter into fully here. For relevant discussion, see, in addition to Dancy 2000, Darwall 1983, Nagel 1970, and Smith 1994.
[^8]: The point is especially well made in Broome 1999. See also Blackburn 1995 and Railton 1997: 76–78.

[^9]: At this point, I am abstracting from the difference between having something as end, which presumably involves intention, and desiring it, which need not, since it doesn't matter for present purposes.
[^10]: The intuitive idea is that what rationality rules out here are incoherent combinations of attitudes. It does not rule in any particular attitude or action on the condition that one has certain others. On this point, see Broome 1999; Dancy 2000; Darwall 1983, 2001; Greenspan 1975; and Hare 1971.
[^11]: Dancy, again, holds that, strictly speaking, any motivational influence must come from normative reasons themselves, not from their acceptance or from any desires that might respond to them. If 'motivation' refers to agents' reasons, that is, to (believed) facts or features of the situation that the agent counted in favor of acting, this seems surely correct. However, we also frequently use 'motivation' to refer to a subjective motivational state. When, for example, we say that someone was motivated by fear, we do not mean that fear was his reason. What the agent had in view that counted in favor of his action was not the fact of his fear, but scary facts his fear "lit up" for him.

[^12]: For a discussion of the psychic state of norm acceptance, see Gibbard 1990: 55–82. See also Hart's discussion of taking an "internal" perspective on rules or law (Hart 1961: 55–57).
[^13]: The Humean view, in this context, is not necessarily the same as Hume's. For an interpretation of Hume along these lines, however, see Bricke 1996.
[^14]: For some similar claims, see Scheffler 2004: 231.
[^15]: For present purposes, we can identify doing *A* with the intention or choice to do *A.*
[^16]: Since states of affairs do not themselves admit of normative regulation, there can be no (unreduced) normative reasons for states—no brute ought-to-be's. (I argue for this claim at greater length in Darwall 2003b. Roughly, when we say that there is reason for something to obtain, all we can defensibly mean is that there is reason for having some attitude toward that state.)

[^17]: Of course, desires can be normatively regulated also—the desirable is what there is reason or we ought to desire. But reasons for acting cannot be reduced to reasons for desiring (although Humeans and non-Humeans alike can accept the principle of instrumental reason—that there is reason to do what will bring about desirable states of the world). For a discussion of this point, and of a fundamental disagreement between Sidgwick and Moore about whether the basic concept of ethics is ought (normative reason) or intrinsic value, see Darwall unpublished.
[^18]: More precisely, my remarks are meant to apply the form of regret that philosophers call "agent-regret." See, for example, Williams 1973: 170–205 and 1981b: 31, 74–75.
[^19]: The significance of this point for practical reason is somewhat masked by the fact that the desire that one do *A* does seem to give rise to one's doing *A*. However, I believe that the reason why this seems to be so is that we accept as an obvious norm of practical reason that we should do what brings about desirable or valuable states, and what seems to us to be true when we have a desire to do *A*, is that doing *A* would be good or valuable. Even here, I think, the desire gives rise to an action (that is, something done for some [apparent] normative reason) only thanks to this additional normative acceptance (or, at least, apparent normative acceptance).

[^20]: Rabinowicz and Ronnøw-Rasmussen (2004) argue that attitudes implicitly contain the distinctive attitude-relevant reasons as part of their content and that appreciating this phenomenon is the solution to the "wrong kind of reasons" problem.
[^21]: This thesis is defended in Quinn 1991.
[^22]: Also in this same vein are: Bond 1983; Dancy 2000; Darwall 1983; Hampton 1998; Pettit and Smith 1990; and Quinn 1991.
[^23]: The experiments are described and analyzed at length in Milgram 1974. For an excellent discussion, see Sabini and Silver 1982: chs. 3–5, 9–11.
[^24]: Of course, they might also have wanted this out of, say, sympathy.

[^25]: Recall that in saying you presupposed these things, I am not making a psychological claim. I am not saying that you actually thought, or that I can reasonably take you to have thought these things (although you may have). I am saying that the second-personal competence of your addressee was a normative felicity condition of your address: the reason you purported to address can be validly addressed *only-if* your addressee has second-personal competence.
[^26]: The details that follow come from Milgram's description of the different setups of the experiment, together with the data (1974: 32–43).
[^27]: The rest (twenty-seven) continued administering shocks until the end (450 volts).

[^28]: Another relevant study was conducted by John Thibaut and Laurens Walker, who were interested in assessing psychological aspects of adversarial systems of criminal justice. Subjects were read a set of facts about an assault case, half incriminating, half exculpatory, and asked to assess guilt or innocence. In one setup, the facts were read to the subjects by one person. In another, they were read by two people, with one "representing" the accused by reading only exculpatory facts, and the other "representing" the prosecution. Subjects who were read the facts in the second setup were significantly likelier to think the defendant innocent than in the first (1975: 42–53).

[^29]: In another Milgram experiment, subjects were subway riders who were asked to give up their seats without any reason that might justify such a request. When Milgram first asked his students to conduct this experiment, he was surprised by their reluctance and the difficulty they reported in executing it. He decided to conduct some trials himself. A newspaper account reports his experience: "But when he approached his first seated passenger, he found himself frozen. 'The words seemed lodged in my trachea and would simply not emerge,' he said in the interview. Retreating, he berated himself: 'What kind of craven coward are you?' A few unsuccessful tries later, he managed to choke out a request. 'Taking the man's seat, I was overwhelmed by the need to behave in a way that would justify my request,' he said 'My head sank between my knees, and I could feel my face blanching. I was not role-playing. I actually felt as if I were going to perish.' " (Michael Luo, " 'Excuse Me. May I Have Your Seat?': Revisiting a Social Experiment, And the Fear That Goes With It," *New York Times*, September 14, 2004.) Years later, one of Milgram's students who ran the experiment remembered a response of one of the subjects whose seat he requested. "The woman snapped: 'If I were standing and you were sitting, I think it'd be very reasonable to ask you for your seat, but I'm not going to give you my seat.' " This seems clear evidence of second-personal psychic phenomena. I am indebted to Tristram McPherson for reminding me of this experiment.

[^30]: Compare here Adam Smith on the natural disposition to defer to superiors owing to empathetic projection into their standpoint: "Upon this disposition of mankind, to go along with all the passions of the rich and the powerful, is founded the distinction of ranks, and the order of society. Our obsequiousness to our superiors more frequently arises from our admiration from the advantages of their situation, than from any private expectations of benefit from their good-will. . . . The strongest motives, the most furious passions, fear, hatred, and resentment, are scarce sufficient to balance this natural disposition to respect them" (1982b: 52–53).
[^31]: A related phenomenon is the familiar experience of simply being persuaded by a vivid representation that another person forcefully makes. (An example: One day I went to my local pool to swim laps. Because work was being done on the glass door connecting to the outside deck, and it was the dead of winter, the water was colder than usual. An elderly woman before me in line turned to me and said, "It's 75 degrees. You can't possibly swim in that." Because she had spoken so authoritatively, I was persuaded. I saw things as she painted them. When I got back to my car, I thought: "You know, 75 degrees isn't *that* cold. I've often swum in 75 degrees and colder." By then, however, I was in my warm car, full of rationalizations about why it was really a better thing that I not swim that day anyway.)

[^32]: Mill argues that although conscience's dictates naturally give the "intuitive" "customary morality" of common sense an advantage, this can be eroded by the "dissolving force of analysis" over time if accepting it is not socially beneficial. Utilitarian morality, on the other hand, has another psychological support that tends to mold conscience in its direction, namely, "the desire to be in unity with our fellow creatures" (1998: ch. 3, §9, 10) Ultimately, time is on utilitarianism's side, and when it becomes widely accepted, conscience will dictate complying with it.
[^33]: Here I draw on Mill's analysis of 'wrong' and moral obligation, which I discussed in Chapter 5.
[^34]: On the relevance of gossip to shared moral reflection, see Sabini and Silver 1982: ch. 5 ("A Plea for Gossip").

[^35]: For a short introduction to the Prisoner's Dilemma, see Barry and Hardin 1982: 11–12, 24–25.
[^36]: Especially good is Fehr and Schmidt 1999. Much of this literature is discussed in Ben-Ner and Putterman 1998. For an excellent critical review, see Anderson 2000. See also Mansbridge 1990. For an excellent argument that punishment-based accounts of human cooperation are significantly better than reciprocity-based accounts within an evolutionary framework, see Sripada 2005.

[^37]: The experiment consisted of six contribution rounds, one set run with paired punishment rounds, one without. To rule out repetition creating cooperation or punishment through tit-for-tat reciprocity or reputation, the group composition continuously changed so that no subject ever met another subject more than once. On the "evolution" of reciprocity in iterated activity, see Axelrod 1984 and Trivers 1971. On reputation effects, see Alexander 1987; Leimar and Hammerstein 2001; Lotem, Fishman, and Stone 1999; Nowak and Sigmund 1998a, 1998b; Wedekind and Milinski 2000.
[^38]: Of course, it can be said that in these cases subjects also got the benefits of satisfying their resentment, but while this is no doubt true, this seems to be a principle-based desire in the sense that resentment involves at least the appearance of a second-personal reason.

[^39]: There were also likely self-interested considerations that were related to the second-personal reasons involved in the reactive attitudes, for example, the desire not to have to live with the painful awareness of being taken advantage of. But these would have been parasitic on the second-personal reasons.
[^40]: Except, of course, a desire to avoid justified sanctions (as in Pufendorf 's Point). But these also would have been parasitic on the second-personal reasons that justify the sanctions.
[^41]: On the importance of "empathic anger" in moral development, see Hoffman 2000: 96–102.

[^42]: Fehr and Rockenbach explain this difference as follows: "Our results suggest that the moral legitimacy of the sanction is a crucial factor. In the public good context the punishment of 'free-riders' is an altruistic act that is considered as morally legitimate.... In the present context, punishment serves the punisher's self-interest and, if it is used to enforce an unfair payoff distribution in favour of the punisher, it decreases altruistic responses" (2003: 137–140). Again, Fehr and his colleagues tend to use 'altruistic' to mean 'cooperative'.
[^43]: They cite Henrich 2000 and Henrich 2001.

[^44]: Unless, that is, he is sophisticated enough to realize that a sophisticated cooperator will be trying to determine whether he is trying to determine this.
[^45]: I discuss Gilbert's ideas in this connection in the next chapter.
[^46]: For discussion of this aspect of Hume and Hutcheson's views, see Darwall 1995a.
[^47]: For another interpretation of Smith that emphasizes interpersonal aspects, see Tugendhat 2004.

[^48]: Consider in this connection what Smith says about those who feel guilt for having unjustly injured others. Even when their victims are ignorant of the crime, the guilty may be moved to confess their guilt and submit "themselves to the resentment of their offended fellow-citizens," in the hopes of some form of reconciliation (Smith 1982a: 118–119).
[^49]: Butler was describing the empirical case for disinterested benevolence.
